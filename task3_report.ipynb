{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfab730e-fc5e-43a5-888a-97e8f865ea2e",
   "metadata": {},
   "source": [
    "## Description of the Task\n",
    "\n",
    "The objective of this task was to **clean and preprocess a raw, real-world dataset** using the\n",
    "**Pandas library in Python**, so that it becomes suitable for further data analysis and machine\n",
    "learning applications.\n",
    "\n",
    "In real-world scenarios, datasets are rarely clean. They often contain missing values,\n",
    "inconsistent formatting, incorrect data types, and duplicate records. If these issues are not\n",
    "handled properly, they can significantly affect the accuracy and reliability of any analysis\n",
    "or model built on the data.\n",
    "\n",
    "Through this task, I focused on identifying and fixing these common data quality issues in a\n",
    "structured and systematic way.\n",
    "\n",
    "Specifically, the task involved:\n",
    "\n",
    "- Loading and inspecting the raw dataset to identify data quality issues  \n",
    "- Handling missing values using appropriate techniques  \n",
    "- Fixing inconsistencies in categorical and text-based columns  \n",
    "- Converting columns into correct data types such as numeric and datetime  \n",
    "- Removing duplicate records  \n",
    "- Saving the cleaned dataset as a new CSV file  \n",
    "\n",
    "## Understanding Data Cleaning (Data Detox)\n",
    "\n",
    "Data cleaning, also referred to as **data detox**, is the process of identifying and correcting\n",
    "errors, inconsistencies, and missing values present in a dataset.\n",
    "\n",
    "While working on this task, I observed that real-world data commonly suffers from:\n",
    "\n",
    "- Missing or null values  \n",
    "- Inconsistent text formatting (e.g., “Male”, “male”, “ MALE ”)  \n",
    "- Incorrect data types (such as dates stored as strings)  \n",
    "- Duplicate rows  \n",
    "- Invalid or corrupted entries  \n",
    "\n",
    "The Pandas library provides a wide range of functions that make it easier to inspect, clean,\n",
    "and transform data efficiently. This task helped me understand how essential data cleaning is\n",
    "before performing any meaningful analysis or machine learning.\n",
    "\n",
    "## Dataset Used\n",
    "\n",
    "For this task, I worked with a **customer-related dataset**.\n",
    "\n",
    "- **Number of records:** Approximately 50,000  \n",
    "- **Number of columns:** 10  \n",
    "\n",
    "### Key Columns in the Dataset\n",
    "\n",
    "- CustomerID  \n",
    "- Name  \n",
    "- Age  \n",
    "- Gender  \n",
    "- Country  \n",
    "- SignupDate  \n",
    "- LastLogin  \n",
    "- TotalPurchase  \n",
    "- PreferredDevice  \n",
    "- Email  \n",
    "\n",
    "### Characteristics of the Dataset\n",
    "\n",
    "While exploring the dataset, I noticed that:\n",
    "\n",
    "- Several numeric and categorical columns contained missing values  \n",
    "- Text-based columns had inconsistent formatting  \n",
    "- Date columns were stored as strings instead of datetime objects  \n",
    "- There was a possibility of duplicate records  \n",
    "\n",
    "## Approach Followed to Solve the Task\n",
    "\n",
    "### 1. Data Inspection and Exploration\n",
    "\n",
    "I began by loading the dataset using Pandas and performing an initial inspection to understand\n",
    "its structure and quality.\n",
    "\n",
    "To do this, I used:\n",
    "\n",
    "- `.head()` to view a few sample rows  \n",
    "- `.info()` to check data types and non-null counts  \n",
    "- `.isnull().sum()` to identify columns with missing values  \n",
    "\n",
    "This step helped me clearly understand which columns required cleaning and what kind of\n",
    "issues were present in the dataset.\n",
    "\n",
    "### 2. Handling Missing Values\n",
    "\n",
    "I handled missing values based on the nature of each column rather than using a single\n",
    "strategy for all of them:\n",
    "\n",
    "- **Age:** Filled missing values using the **median**, as age data can contain outliers  \n",
    "- **Gender and Country:** Filled missing values using the **mode**, which is suitable for\n",
    "  categorical variables  \n",
    "- **TotalPurchase:** Filled missing values using the **mean**, since it is a continuous\n",
    "  numerical feature  \n",
    "\n",
    "This approach helped preserve the overall distribution of the data while minimizing bias.\n",
    "\n",
    "### 3. Fixing Text and Categorical Inconsistencies\n",
    "\n",
    "To ensure consistency across categorical columns, I cleaned and standardized text data:\n",
    "\n",
    "- Removed leading and trailing whitespaces  \n",
    "- Converted text into a uniform format:\n",
    "  - **Gender** → lowercase  \n",
    "  - **Country** → title case  \n",
    "  - **PreferredDevice** → lowercase  \n",
    "\n",
    "This step was important to avoid treating the same category as different values during\n",
    "analysis.\n",
    "\n",
    "### 4. Correcting Data Types\n",
    "\n",
    "Correct data types are essential for accurate analysis and model building. I converted\n",
    "columns to appropriate data types as follows:\n",
    "\n",
    "- Converted **SignupDate** and **LastLogin** to datetime format  \n",
    "- Used coercion to safely handle invalid date entries  \n",
    "- Converted **Age** to integer type  \n",
    "- Converted **TotalPurchase** to float type  \n",
    "\n",
    "This ensured that numerical and date-based operations could be performed without errors.\n",
    "\n",
    "### 5. Removing Duplicate Records\n",
    "\n",
    "Duplicate records can distort analysis and lead to misleading insights.\n",
    "\n",
    "- I checked the dataset for duplicate rows  \n",
    "- All identified duplicates were removed to maintain data integrity  \n",
    "\n",
    "### 6. Final Validation and Saving the Dataset\n",
    "\n",
    "After completing all cleaning steps, I performed a final validation to ensure that:\n",
    "\n",
    "- All columns had correct data types  \n",
    "- No unintended missing values remained  \n",
    "- The dataset was consistent and analysis-ready  \n",
    "\n",
    "Finally, I saved the cleaned dataset as a **new CSV file**, preserving the original raw dataset\n",
    "as a backup.\n",
    "\n",
    "---\n",
    "\n",
    "## Outcomes and Learnings\n",
    "\n",
    "Through this task, I gained hands-on experience in **cleaning and preprocessing real-world\n",
    "datasets using Pandas**.\n",
    "\n",
    "Key learnings from this task include:\n",
    "\n",
    "- The importance of thoroughly inspecting data before cleaning  \n",
    "- Choosing appropriate strategies for handling different types of missing values  \n",
    "- Maintaining consistency in categorical data to avoid logical errors  \n",
    "- The significance of preserving raw data before applying transformations  \n",
    "\n",
    "Overall, this task strengthened my understanding of data preprocessing and highlighted how\n",
    "crucial data cleaning is in the data science workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73609205-77b8-4b0f-b4ad-e3e692a0c359",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
