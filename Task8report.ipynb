{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0758de5f-f194-4329-9523-d11aa31fc195",
   "metadata": {},
   "source": [
    "## Description of the Task\n",
    "\n",
    "The objective of this task is to apply a **K-Nearest Neighbors (KNN)** classifier to a medical dataset\n",
    "and study how individual features influence the model’s performance.\n",
    "\n",
    "Specifically, the task involves:\n",
    "\n",
    "- Training a KNN model to classify breast tumors as **malignant** or **benign**\n",
    "- Evaluating the model using multiple performance metrics\n",
    "- Performing a **feature ablation study**, where one feature is removed at a time to observe\n",
    "  its impact on classification accuracy and reliability\n",
    "\n",
    "This task helps in understanding both **how KNN works** and **why feature selection is important**,\n",
    "especially in sensitive domains like healthcare.\n",
    "\n",
    "## Understanding K-Nearest Neighbors (KNN)\n",
    "\n",
    "K-Nearest Neighbors is a **supervised, distance-based classification algorithm**.  \n",
    "Instead of learning mathematical equations, KNN makes predictions by comparing new data points\n",
    "with existing labeled data.\n",
    "\n",
    "When a new data point is given, the algorithm:\n",
    "\n",
    "1. Calculates the distance between the new point and all training points  \n",
    "2. Selects the **K nearest data points**  \n",
    "3. Assigns the class that appears most frequently among those neighbors  \n",
    "\n",
    "In this task, **K = 5**, meaning the algorithm looks at the **5 closest tumors** and predicts\n",
    "the class based on **majority voting**.\n",
    "\n",
    "\n",
    "## Visual Intuition of KNN\n",
    "\n",
    "Imagine a 2D graph where:\n",
    "\n",
    "- Each dot represents a tumor  \n",
    "- **Red dots** represent malignant tumors  \n",
    "- **Blue dots** represent benign tumors  \n",
    "\n",
    "When a new tumor appears on the graph, KNN draws a circle around it and looks at the nearest\n",
    "neighbors inside the circle.\n",
    "\n",
    "- If most nearby points are red → **Predicted malignant**\n",
    "- If most nearby points are blue → **Predicted benign**\n",
    "\n",
    "This intuitive **“neighborhood voting”** is the core idea behind KNN.\n",
    "\n",
    "## Importance of Feature Scaling in KNN\n",
    "\n",
    "KNN relies on **distance calculations**, usually Euclidean distance.  \n",
    "However, tumor features exist on very different numerical scales:\n",
    "\n",
    "- Area-related features can have values in the **hundreds**\n",
    "- Smoothness-related features are **small decimal values**\n",
    "\n",
    "If features are not scaled:\n",
    "\n",
    "- Large-valued features dominate distance calculations  \n",
    "- The model becomes biased and less accurate  \n",
    "\n",
    "To address this issue, **StandardScaler** is used to normalize all features so that each feature\n",
    "contributes equally to distance computation.\n",
    "\n",
    "## Dataset Used\n",
    "\n",
    "The **Breast Cancer Wisconsin (Diagnostic)** dataset was used in this task.\n",
    "\n",
    "- **Total samples:** 569  \n",
    "- **Target variable:** `diagnosis`  \n",
    "  - Malignant (M) → 1  \n",
    "  - Benign (B) → 0  \n",
    "- **Features:**  \n",
    "  - 30 numerical measurements related to tumor size, shape, and texture  \n",
    "- **Missing values:** None  \n",
    "\n",
    "This dataset is widely used for medical classification and benchmarking\n",
    "machine learning models.\n",
    "\n",
    "## Approach Followed to Solve the Task\n",
    "\n",
    "### 1. Data Preprocessing\n",
    "\n",
    "The preprocessing steps were handled using a **machine learning pipeline** to ensure\n",
    "consistency and robustness.\n",
    "\n",
    "The steps included:\n",
    "\n",
    "- Encoding the target variable (M → 1, B → 0)\n",
    "- Separating features (X) and target (y)\n",
    "- Splitting the dataset into training (80%) and testing (20%) sets\n",
    "  using **stratified sampling**\n",
    "- Handling missing values using **mean imputation**\n",
    "- Normalizing all features using **StandardScaler**\n",
    "\n",
    "Using a pipeline ensures that preprocessing steps such as imputation and scaling\n",
    "are applied consistently during both training and testing, preventing data leakage.\n",
    "\n",
    "### 2. Training the KNN Model\n",
    "\n",
    "A **KNN classifier** was trained using a pipeline that combined preprocessing\n",
    "and classification steps.\n",
    "\n",
    "- **Number of neighbors (K):** 5  \n",
    "- Preprocessing (imputation and scaling) and model training were performed together\n",
    "  using a single pipeline  \n",
    "\n",
    "This approach simplifies the workflow and ensures that the same transformations\n",
    "are applied whenever the model is trained or evaluated.\n",
    "\n",
    "### 3. Model Evaluation\n",
    "\n",
    "To evaluate the model reliably, the following metrics were used:\n",
    "\n",
    "- **Accuracy** – overall correctness of predictions  \n",
    "- **Precision** – correctness of malignant predictions  \n",
    "- **Recall** – ability to detect malignant tumors  \n",
    "- **F1-score** – balance between precision and recall  \n",
    "\n",
    "Using multiple metrics is essential in medical datasets to avoid misleading conclusions.\n",
    "\n",
    "## Feature Ablation Study\n",
    "\n",
    "Feature ablation is a technique used to understand **feature importance** by:\n",
    "\n",
    "- Removing one feature at a time  \n",
    "- Retraining the model  \n",
    "- Observing the change in performance  \n",
    "\n",
    "If removing a feature causes a significant drop in performance,\n",
    "that feature is considered important.\n",
    "\n",
    "### How Feature Ablation Was Performed\n",
    "\n",
    "For each of the 30 features:\n",
    "\n",
    "- One feature was removed from the dataset  \n",
    "- The data was split again into training and testing sets  \n",
    "- A preprocessing + KNN pipeline (imputation, scaling, and classification) was rebuilt  \n",
    "- The model was retrained with **K = 5**  \n",
    "- Accuracy, precision, recall, and F1-score were recorded  \n",
    "\n",
    "Only **one feature was removed at a time**, ensuring a fair and controlled comparison.\n",
    "\n",
    "## Visualization and Interpretation\n",
    "\n",
    "### Feature Ablation Visualization\n",
    "\n",
    "A bar chart was plotted showing:\n",
    "\n",
    "- **Accuracy values when each feature was removed**\n",
    "\n",
    "### Interpretation of the Visualization\n",
    "\n",
    "- Features whose removal caused the **largest drop in accuracy** are the most influential  \n",
    "- Features with minimal impact are less important for classification  \n",
    "\n",
    "The visualization clearly highlighted that features related to:\n",
    "\n",
    "- Tumor **radius**\n",
    "- **Area**\n",
    "- **Perimeter**\n",
    "- **Concavity**\n",
    "\n",
    "play a critical role in breast cancer diagnosis.\n",
    "\n",
    "## Outcomes and Learnings\n",
    "\n",
    "Through this task, I gained a clear understanding of how the K-Nearest Neighbors algorithm\n",
    "works by making predictions based on similarity and distance between data points.\n",
    "\n",
    "I also realized how crucial feature scaling is for distance-based models, as unscaled features\n",
    "can easily mislead the algorithm.\n",
    "\n",
    "The feature ablation study helped me understand which tumor characteristics truly matter\n",
    "for accurate classification. By removing one feature at a time and observing the change\n",
    "in performance, I could see how certain features play a much bigger role than others.\n",
    "\n",
    "Overall, this task demonstrated how machine learning can be meaningfully applied in\n",
    "medical diagnosis and highlighted the importance of careful preprocessing, evaluation,\n",
    "and analysis when working with real-world healthcare data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0b0948-9a0d-40ef-885f-5a8bc151e3be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
